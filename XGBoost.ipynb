{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XGBoost:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] load dataset : ./dataset_test_case_01.csv\n",
      "[*] train set split\n",
      "[*] train XGBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XGBoost:   0%|          | 0/5 [00:02<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] train result : \n",
      "\tAccuracy \t:  0.9311506332524926\n",
      "\tPercision \t:  0.9330167542116381\n",
      "\tRecall \t\t:  0.9311506332524926\n",
      "\tF1-Score \t:  0.931561107413692\n",
      "[*] Confusion matrix : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 61\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39mF1-Score \u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m'\u001b[39m, f1)\n\u001b[1;32m     60\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m[*] Confusion matrix : \u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 61\u001b[0m matrix \u001b[39m=\u001b[39m confusion_matrix(y_test, y_pred, labels\u001b[39m=\u001b[39;49mlabel, normalize\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtrue\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     62\u001b[0m sns\u001b[39m.\u001b[39mheatmap(matrix, annot\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, xticklabels\u001b[39m=\u001b[39mlabel, yticklabels\u001b[39m=\u001b[39mlabel, cmap\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mBlues\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     63\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m'\u001b[39m\u001b[39mPredicted\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:330\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[39melif\u001b[39;00m y_true\u001b[39m.\u001b[39msize \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    329\u001b[0m         \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mzeros((n_labels, n_labels), dtype\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m)\n\u001b[0;32m--> 330\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(np\u001b[39m.\u001b[39;49mintersect1d(y_true, labels)) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    331\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAt least one label specified must be in y_true\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    333\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mintersect1d\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/numpy/lib/arraysetops.py:455\u001b[0m, in \u001b[0;36mintersect1d\u001b[0;34m(ar1, ar2, assume_unique, return_indices)\u001b[0m\n\u001b[1;32m    453\u001b[0m     aux \u001b[39m=\u001b[39m aux[aux_sort_indices]\n\u001b[1;32m    454\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 455\u001b[0m     aux\u001b[39m.\u001b[39;49msort()\n\u001b[1;32m    457\u001b[0m mask \u001b[39m=\u001b[39m aux[\u001b[39m1\u001b[39m:] \u001b[39m==\u001b[39m aux[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m    458\u001b[0m int1d \u001b[39m=\u001b[39m aux[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][mask]\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "# <-- import library -->\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "%matplotlib inline\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# <-- config -->\n",
    "_TODAY = datetime.datetime.today().date()\n",
    "dataset_dic = \"./dataset/\"\n",
    "dataset_list = [\"./dataset_test_case_01.csv\", \"./dataset_test_case_02.csv\", \"dataset_test_case_03_Digital.csv\", \"dataset_test_case_03_Analog.csv\", \"dataset_test_case_04.csv\"]\n",
    "IoT_list = ['Heart_Rate', 'Soil_Moisture', 'Sound_Sensor', 'Temperature_and_Humidity', 'Water_Level', 'phValue']\n",
    "test_list = ['Digital_Output', 'Analog_Output']\n",
    "features = ['src.port', 'flow_duration', 'mqtt_duration', 'mqtt_connection_duration', 'mqtt_connection_ack_duration', 'mqtt_disconnection_duration', 'IoT_label', 'test_label']\n",
    "target_dict = {dataset_list[0] : features[-2], \n",
    "          dataset_list[1] : features[-1],\n",
    "          dataset_list[2] : features[-2], \n",
    "          dataset_list[3] : features[-2],\n",
    "          dataset_list[4] : features[-2]}\n",
    "\n",
    "# <-- train -->\n",
    "for dataset in tqdm(dataset_list, desc='XGBoost', position=0):\n",
    "    print('[*] load dataset : ' + dataset)\n",
    "    df = pd.read_csv(dataset_dic + dataset)\n",
    "    # <-- train set split -->\n",
    "    print('[*] train set split')\n",
    "    train_features = features[1:-2]\n",
    "    target = target_dict[dataset]\n",
    "\n",
    "    label = df[target].unique()\n",
    "    class_mapping = {cls: i for i, cls in enumerate(label)}\n",
    "    df[target] = df[target].map(class_mapping)\n",
    "\n",
    "    X = df[train_features]\n",
    "    y = df[target]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=43)\n",
    "\n",
    "    # <-- train XGBoost -->\n",
    "    print('[*] train XGBoost')\n",
    "    xgb_model = xgb.XGBClassifier()\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = xgb_model.predict(X_test)\n",
    "    print('[*] train result : ')\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print('\\tAccuracy \\t: ', accuracy)\n",
    "    percision = precision_score(y_test, y_pred, average='weighted')\n",
    "    print('\\tPercision \\t: ', percision)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    print('\\tRecall \\t\\t: ', recall)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print('\\tF1-Score \\t: ', f1)\n",
    "\n",
    "    print('[*] Confusion matrix : ')\n",
    "    matrix = confusion_matrix(y_test, y_pred, labels=class_mapping, normalize='true')\n",
    "    sns.heatmap(matrix, annot=True, xticklabels=label, yticklabels=label, cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"[*] Feature Importances: \\n{0}\\n\".format(xgb_model.feature_importances_))\n",
    "    for name, value in zip(train_features, xgb_model.feature_importances_):\n",
    "        print('{0}: {1:.3f}'.format(name, value))\n",
    "    sns.barplot(x=xgb_model.feature_importances_, y=train_features)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
